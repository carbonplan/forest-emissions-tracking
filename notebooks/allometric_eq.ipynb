{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fsspec\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "from carbonplan_trace.v1.glas_preprocess import *\n",
    "from carbonplan_trace.v1.glas_height_metrics import *\n",
    "from carbonplan_trace.v1.glas_allometric_eq import *\n",
    "from carbonplan_trace.v1.utils import *\n",
    "\n",
    "from dask.diagnostics import ProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url01 = f\"gs://carbonplan-scratch/trace_scratch/wa_glah01.zarr\"\n",
    "mapper01 = fsspec.get_mapper(url01)\n",
    "data01 = xr.open_zarr(mapper01).chunk({\"record_index\": 1000, \"shot_number\": 10})\n",
    "\n",
    "url14 = f\"gs://carbonplan-scratch/trace_scratch/wa_glah14.zarr\"\n",
    "mapper14 = fsspec.get_mapper(url14)\n",
    "data14 = xr.open_zarr(mapper14).chunk({\"record_index\": 1000, \"shot_number\": 10})\n",
    "\n",
    "combined = data14.merge(data01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = combined.chunk({\"record_index\": 1000, \"shot_number\": 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = 'gs://carbonplan-scratch/trace_scratch/wa_combined.zarr'\n",
    "# save_to_zarr(combined, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(ds, n):\n",
    "    # preprocess\n",
    "    if \"rec_wf_sample_distance\" in ds and \"processed_wf\" in ds:\n",
    "        print(\"skipping preprocess\")\n",
    "        pass\n",
    "    else:\n",
    "        print(\"preprocess\")\n",
    "        t1 = time.time()\n",
    "        ds = preprocess(ds).compute()\n",
    "        t2 = time.time()\n",
    "\n",
    "    #         url = 'gs://carbonplan-scratch/trace_scratch/wa_preprocessed.zarr'\n",
    "    #         save_to_zarr(ds, url, ['rec_wf_sample_distance', 'processed_wf'])\n",
    "\n",
    "    # specific height metrics (still in units of \"distance from satellite\")\n",
    "    ds[\"meanH_distance\"] = get_mean_distance(\n",
    "        bins=ds.rec_wf_sample_distance, wf=ds.processed_wf\n",
    "    )\n",
    "\n",
    "    # percentile distance\n",
    "    percentiles = [10, 90]  # get 10th and 90th percentiles\n",
    "    percentile_distances = get_percentile_distance(\n",
    "        bins=ds.rec_wf_sample_distance,\n",
    "        wf=ds.processed_wf,\n",
    "        percentiles=percentiles,\n",
    "    )\n",
    "    for p in percentiles:\n",
    "        ds[f\"{p}th_distance\"] = percentile_distances[p]\n",
    "\n",
    "    print(\"getting ground peak distance\")\n",
    "    # get ground peak distance\n",
    "    ds[\"ground_peak_distance\"] = get_ground_peak_distance(\n",
    "        bins=ds.rec_wf_sample_distance, wf=ds.processed_wf\n",
    "    )\n",
    "\n",
    "    # get heights from distance\n",
    "    list_of_distance_vars = [\n",
    "        \"meanH_distance\",\n",
    "        \"10th_distance\",\n",
    "        \"90th_distance\",\n",
    "    ]\n",
    "    ds = get_heights_from_distance(\n",
    "        ds=ds,\n",
    "        list_of_distance_vars=list_of_distance_vars,\n",
    "        referece_distance_var=\"ground_peak_distance\",\n",
    "    )\n",
    "\n",
    "    ds = apply_allometric_equation(ds).compute()\n",
    "    t3 = time.time()\n",
    "\n",
    "    print(f\"preprocess took {(t2-t1) / 60. / n} min per record\")\n",
    "    print(f\"other processes took {(t3-t2) / 60. / n} min per record\")\n",
    "\n",
    "    return ds\n",
    "\n",
    "\n",
    "# could start a cluster\n",
    "# ds.to_zarr('cloud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy timing\n",
    "# on average each record takes ~0.05 mins for preprocessing if processing 10 records at a time\n",
    "# on average each record takes ~0.005 mins for other process if processing 10 records at a time\n",
    "# total = 139.15 mins\n",
    "\n",
    "# on average each record takes ~0.005 mins for preprocessing if processing 100 records at a time\n",
    "# on average each record takes ~0.0005 mins for other process if processing 100 records at a time\n",
    "\n",
    "# on average each record takes ~0.001 mins for preprocessing if processing 1000 records at a time\n",
    "# on average each record takes ~7 * 10-5 mins for other process if processing 1000 records at a time\n",
    "\n",
    "# on average each record takes ~0.0008 mins for preprocessing if processing 10000 records at a time\n",
    "# on average each record takes ~4 * 10-5 mins for other process if processing 10000 records at a time\n",
    "\n",
    "n = 30000\n",
    "for i in range(1):\n",
    "    sub = combined.isel(record_index=slice(i * n, (i + 1) * n))\n",
    "    p = main(sub, n)\n",
    "    print(p.biomass.values[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"gs://carbonplan-scratch/trace_scratch/wa_processed.zarr\"\n",
    "save_to_zarr(p, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = p.sel(record_index=22232245, shot_number=33)\n",
    "plot_shot(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyproj import transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_lat_lon(lat, lon):\n",
    "    return np.array(transform(4326, 32610, lat, lon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.apply_ufunc(\n",
    "    transform_lat_lon,\n",
    "    sub.lat,\n",
    "    sub.lon,\n",
    "    vectorize=True,\n",
    "    dask='parallelized',\n",
    "    dask_gufunc_kwargs={'allow_rechunk': 1},\n",
    "    output_core_dims=[['lat_lon']],\n",
    "    output_sizes=\n",
    "    output_dtypes=np.float64\n",
    ").compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"index.csv\")\n",
    "df.head()\n",
    "\n",
    "x0, y0, x1, y1 = [-124.763068, 45.543541, -116.915989, 49.002494]\n",
    "time_start = \"2003-02-20T00:00:00Z\"\n",
    "time_end = \"2009-10-11T23:59:59Z\"\n",
    "\n",
    "df_wa = df[\n",
    "    (time_start < df[\"SENSING_TIME\"])\n",
    "    & (df[\"SENSING_TIME\"] < time_end)\n",
    "    & (df[\"NORTH_LAT\"] < y1)\n",
    "    & (df[\"SOUTH_LAT\"] > y0)\n",
    "    & (df[\"WEST_LON\"] > x0)\n",
    "    & (df[\"EAST_LON\"] < x1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landsat_times = pd.to_datetime(df_wa.SENSING_TIME.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.DataArray(dims=[\"landsat_time\"], coords=[landsat_times])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nearest_time(glastime, list_of_time):\n",
    "    # find nearest \n",
    "    \n",
    "xr.apply_ufunc(\n",
    "    get_nearest_time,\n",
    "    sub.time,\n",
    "    ds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each glas\n",
    "\n",
    "ds.sel(landsat_time=glas_time, method=\"nearest\")\n",
    "\n",
    "# avail_times = list_of_time\n",
    "\n",
    "# sub.sel(time=1, method=\n",
    "\n",
    "# i have list of available timestamps\n",
    "# for each record tell me which time is closest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_wf(bins, wf, target, area_to_include):\n",
    "    \"\"\"\n",
    "    not vectorized\n",
    "    if area_to_include = 'above', the function returns the area between the target location to the \"upper bound\" (larger value) bin\n",
    "    if area_to_include = 'below', the function returns the area between the target location to the \"lower bound\" (smaller value) bin\n",
    "    \"\"\"\n",
    "    upper_ind = np.where(bins > target)[0].max()\n",
    "    lower_ind = np.where(bins < target)[0].min()\n",
    "    # since bins goes from large to small values, the \"upper bound\" index would be smaller than the \"lower bound\" index\n",
    "    assert lower_ind - upper_ind == 1\n",
    "\n",
    "    x_upper = bins[upper_ind]\n",
    "    x_lower = bins[lower_ind]\n",
    "    y_upper = wf[upper_ind]\n",
    "    y_lower = wf[lower_ind]\n",
    "\n",
    "    x_mid = (x_upper + x_lower) / 2.0\n",
    "    x_span = x_upper - x_lower\n",
    "\n",
    "    if area_to_include == \"above\":\n",
    "        if target < x_mid:\n",
    "            energy = (\n",
    "                (x_mid - target) / x_span * y_lower\n",
    "            )  # energy to add to the lower bin\n",
    "            bin_to_modify = lower_ind\n",
    "        else:\n",
    "            energy = (\n",
    "                (x_mid - target) / x_span * y_upper\n",
    "            )  # energy to subtract out of the upper bin\n",
    "            bin_to_modify = upper_ind\n",
    "    elif area_to_include == \"below\":\n",
    "        if target < x_mid:\n",
    "            energy = (\n",
    "                (target - x_mid) / x_span * y_lower\n",
    "            )  # energy to subtract out of the lower bin\n",
    "            bin_to_modify = lower_ind\n",
    "        else:\n",
    "            energy = (\n",
    "                (target - x_mid) / x_span * y_upper\n",
    "            )  # energy to add to the upper bin\n",
    "            bin_to_modify = upper_ind\n",
    "    else:\n",
    "        raise NotImplementedError(\n",
    "            \"Please specify whether we want to include area above or below the target to the bounds\"\n",
    "        )\n",
    "\n",
    "    return bin_to_modify, energy\n",
    "\n",
    "\n",
    "def interpolate_and_select_valid_area(bins, wf, beg, end):\n",
    "    \"\"\"\n",
    "    not vectorized\n",
    "    \"\"\"\n",
    "    # initialize output\n",
    "    output = np.zeros(len(wf))\n",
    "\n",
    "    # within signal beginning and end locations, set otuput to be equal to input wf\n",
    "    valid = np.where((bins > beg) & (bins < end))[0]\n",
    "    output[valid] = wf[valid]\n",
    "\n",
    "    # for the begining and end bin, interpolate\n",
    "    # bins goes from large values (furthest away from satellite) to small (closest to satellite)\n",
    "    bin_to_modify, energy = interpolate_wf(bins, wf, beg, \"above\")\n",
    "    bins[bin_to_modify] += energy\n",
    "    bin_to_modify, energy = interpolate_wf(bins, wf, end, \"below\")\n",
    "    bins[bin_to_modify] += energy\n",
    "\n",
    "    # min at 0\n",
    "    output = np.maximum(output, 0)\n",
    "\n",
    "    return output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
