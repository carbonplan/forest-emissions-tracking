{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width=\"100\" src=\"https://carbonplan-assets.s3.amazonaws.com/monogram/dark-small.png\" style=\"margin-left:0px;margin-top:20px\"/>\n",
    "\n",
    "Forest Emissions Tracking - Phase I\n",
    "===================================\n",
    "\n",
    "_by Joe Hamman and Jeremy Freeman (CarbonPlan)_\n",
    "\n",
    "March 29, 2020\n",
    "\n",
    "## Introduction\n",
    "In general, greenhouse gasses (GHGs) arising from forest land use changes can be attributed to both natural factors (e.g. wildfire) and human activities (e.g. deforestation). Our approach is to build upon an existing body of research that has provided high-resolution satellite-based estimates of aboveground biomass (Spawn et al., 2020), forest cover change (Hansen et al., 2013), and change attribution (Curtis et al., 2018). While many of the necessary data products already exist, we can integrate, extend, or update these resources to provide global, current estimates that can be integrated with the other resources produced by the coalition.\n",
    "\n",
    "Specifically, for any given spatial extent and time duration ($t1$ to $t2$), we can use three quantities — existing biomass, forest cover change, and change attribution — to estimate the effective GHG emissions from land use changes. The simplest estimate is:\n",
    "\n",
    "$\\Delta Biomass (t) = TotalBiomass (t) * \\Delta ForestCover (\\%)$\n",
    "\n",
    "$Emissions (tCO_2) = \\Delta Biomass (t) * 0.5 (tC/t) * 3.67 (tC02 / tC)$\n",
    "\n",
    "where $\\Delta ForestCover$ is the fraction of pixels within the given spatial extent that experienced a stand-replacement disturbance between $t1$ and $t2$. The $TotalBiomass$ is estimated as the aboveground biomass at time $t1$. This estimate can be further refined by attributing, for each pixel, the source of forest cover loss (e.g. wildfire, deforestation, etc.), and using those sources to express emissions fractionally and/or exclude certain categories from total estimates (e.g. rotational clear-cutting within tree plantations). Pixel-wise estimates can then be aggregated into province and country-wide estimates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "To begin, we'll import a handful of Python libraries and set a few constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import dask\n",
    "import intake\n",
    "import xarray as xr\n",
    "from tqdm import tqdm\n",
    "import numcodecs\n",
    "\n",
    "\n",
    "TC02_PER_TC = 3.67\n",
    "TC_PER_TBM = 0.5\n",
    "SQM_PER_HA = 10000\n",
    "ORNL_SCALING = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_gateway import Gateway\n",
    "\n",
    "gateway = Gateway()\n",
    "options = gateway.cluster_options()\n",
    "options.worker_cores = 2\n",
    "options.worker_memory = 24\n",
    "cluster = gateway.new_cluster(cluster_options=options)\n",
    "cluster.adapt(minimum=1, maximum=300)\n",
    "cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = cluster.get_client()\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data catalog\n",
    "cat = intake.open_catalog(\"https://raw.githubusercontent.com/carbonplan/forest-emissions-tracking/master/catalog.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fsspec\n",
    "\n",
    "with fsspec.open('https://storage.googleapis.com/earthenginepartners-hansen/GFC-2018-v1.6/treecover2000.txt') as f:\n",
    "    lines = f.read().decode().splitlines() \n",
    "print(len(lines))\n",
    "\n",
    "# all tiles\n",
    "# lats = []\n",
    "# lons = []\n",
    "# for line in lines:\n",
    "#     pieces = line.split('_')\n",
    "#     lats.append(pieces[-2])\n",
    "#     lons.append(pieces[-1].split('.')[0])\n",
    "    \n",
    "# conus tiles\n",
    "conus_lats = ['60N', '50N', '40N', '30N']\n",
    "conus_lons = ['140W', '130W', '120W', '110W', '100W', '90W', '80W', '70W', '60W']\n",
    "\n",
    "# all tiles\n",
    "lats = []\n",
    "lons = []\n",
    "for line in lines:\n",
    "    pieces = line.split('_')\n",
    "    lat = pieces[-2]\n",
    "    lon = pieces[-1].split('.')[0]\n",
    "    \n",
    "    if (lat in conus_lats) and (lon in conus_lons):\n",
    "        lats.append(lat)\n",
    "        lons.append(lon)\n",
    "print(len(lats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _preprocess(da, lat=None, lon=None):\n",
    "    da = da.rename({\"x\": \"lon\", \"y\": \"lat\"}).squeeze(drop=True)\n",
    "    if lat is not None:\n",
    "        da = da.assign_coords(lat=lat, lon=lon)\n",
    "    return da\n",
    "\n",
    "\n",
    "def open_hansen_2018_tile(lat, lon, emissions=False):\n",
    "    ds = xr.Dataset()\n",
    "\n",
    "    # Min Hansen data\n",
    "    variables = [\"treecover2000\", \"gain\", \"lossyear\", \"datamask\"] #, \"first\", \"last\"]\n",
    "    for v in variables:\n",
    "        da = cat.hansen_2018(variable=v, lat=lat, lon=lon).to_dask().pipe(_preprocess)\n",
    "        # force coords to be identical\n",
    "        if ds:\n",
    "            da = da.assign_coords(lat=ds.lat, lon=ds.lon)\n",
    "        ds[v] = da\n",
    "\n",
    "    ds[\"treecover2000\"] /= 100.0\n",
    "    ds[\"lossyear\"] += 2000\n",
    "\n",
    "    # Hansen biomass\n",
    "    ds[\"agb\"] = (\n",
    "        cat.hansen_biomass(lat=lat, lon=lon).to_dask().pipe(_preprocess, lat=ds.lat, lon=ds.lon)\n",
    "    )\n",
    "    if emissions:\n",
    "        # Hansen emissions\n",
    "        ds[\"emissions_ha\"] = (\n",
    "            cat.hansen_emissions_ha(lat=lat, lon=lon)\n",
    "            .to_dask()\n",
    "            .pipe(_preprocess, lat=ds.lat, lon=ds.lon)\n",
    "        )\n",
    "        ds[\"emissions_px\"] = (\n",
    "            cat.hansen_emissions_px(lat=lat, lon=lon)\n",
    "            .to_dask()\n",
    "            .pipe(_preprocess, lat=ds.lat, lon=ds.lon)\n",
    "        )\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open a single 10x10degree tile of the Hansen 30x30m data\n",
    "lat = lats[1]\n",
    "lon = lons[1]\n",
    "box = dict(lat=slice(0, 40000, 100), lon=slice(0, 40000, 100))\n",
    "\n",
    "ds = open_hansen_2018_tile(lat, lon)\n",
    "display(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = {'emissions': {'compressor': numcodecs.Blosc()}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_emissions(ds):\n",
    "    d_biomass = ds['agb'] * ds['d_treecover']\n",
    "    emissions = d_biomass * TC_PER_TBM * TC02_PER_TC\n",
    "    return emissions\n",
    "\n",
    "\n",
    "def calc_one_tile(ds):\n",
    "    # calculate d_treecover\n",
    "    years = xr.DataArray(range(2001, 2019), dims=('year', ), name='year')\n",
    "    loss_frac = []\n",
    "    for year in years:\n",
    "        loss_frac.append(xr.where((ds['lossyear'] == year), ds['treecover2000'], 0))\n",
    "    ds['d_treecover'] = xr.concat(loss_frac, dim=years)\n",
    "    ds['emissions'] = calc_emissions(ds)\n",
    "    return ds\n",
    "\n",
    "\n",
    "@dask.delayed\n",
    "def process_one_tile(lat, lon):\n",
    "    url = f'gs://carbonplan-scratch/global-forest-emissions/{lat}_{lon}.zarr'\n",
    "    \n",
    "    if '.zmetadata' in url:\n",
    "        # skip - dataset is already complete\n",
    "        return url\n",
    "    mapper = fsspec.get_mapper(url)\n",
    "\n",
    "    with dask.config.set(scheduler='threads'):\n",
    "        ds = open_hansen_2018_tile(lat, lon)\n",
    "        ds = calc_one_tile(ds)[['emissions']]\n",
    "        ds = ds.chunk({'lat': 4000, 'lon': 4000, 'year': 2})\n",
    "        ds.to_zarr(mapper, encoding=encoding, mode='w')\n",
    "        return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles = []\n",
    "for lat, lon in tqdm(list(zip(lats, lons))):\n",
    "    tiles.append(client.persist(process_one_tile(lat, lon), retries=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()\n",
    "cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:notebook] *",
   "language": "python",
   "name": "conda-env-notebook-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
